import os
import re
import streamlit as st
from datetime import date, datetime
import yt_dlp
import pandas as pd
import random # –†–æ–∑–∫–æ–º–µ–Ω—Ç–æ–≤–∞–Ω–æ –¥–ª—è gpt_comment_summary
import json # –î–æ–¥–∞–Ω–æ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É JSON –≤—ñ–¥ GPT
from googleapiclient.discovery import build
from openai import OpenAI

# nltk —Ç–∞ SentimentIntensityAnalyzer –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ, —è–∫—â–æ sentiment_analysis –≤–∏–¥–∞–ª–µ–Ω–æ
# sklearn —Ç–∞ matplotlib –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è

# --- –ö–ª—é—á—ñ API (—Ç–µ–ø–µ—Ä –∑—ñ Streamlit Secrets) ---
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY")
YT_API_KEY = st.secrets.get("YOUTUBE_API_KEY")

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª—ñ—î–Ω—Ç–∞ OpenAI
if not OPENAI_API_KEY:
    st.error("–ö–ª—é—á OpenAI API (OPENAI_API_KEY) –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É Streamlit Secrets. –ë—É–¥—å –ª–∞—Å–∫–∞, –¥–æ–¥–∞–π—Ç–µ –π–æ–≥–æ.")
    client = None
else:
    client = OpenAI(api_key=OPENAI_API_KEY)

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–ª—é—á–∞ YouTube Data API
if not YT_API_KEY:
    st.warning(
        "–ö–ª—é—á YouTube Data API (YOUTUBE_API_KEY) –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É Streamlit Secrets. –§—É–Ω–∫—Ü—ñ—ó, —â–æ –π–æ–≥–æ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å, –º–æ–∂—É—Ç—å –Ω–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏.")

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏ (–º–∞—î –±—É—Ç–∏ –ø–µ—Ä—à–æ—é –∫–æ–º–∞–Ω–¥–æ—é Streamlit)
st.set_page_config(page_title="YouTube Analytics Agent", layout="wide")

st.title("YouTube Analytics Agent")
st.markdown(
    """
    –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π –∞–≥–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É YouTube-–∫–∞–Ω–∞–ª—ñ–≤.
    """
)

# --- –§—É–Ω–∫—Ü—ñ—ó ---

def extract_channel_id(url_input):
    """–í–∏—Ç—è–≥—É—î ID –∫–∞–Ω–∞–ª—É –∞–±–æ —ñ–º'—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑ URL."""
    match_user = re.search(r"(?:https?://)?(?:www\.)?youtube\.com/@([^/?]+)", url_input)
    if match_user:
        return match_user.group(1)
    match_channel = re.search(r"(?:https?://)?(?:www\.)?youtube\.com/channel/([^/?]+)", url_input)
    if match_channel:
        return match_channel.group(1)
    return None


def fetch_video_metadata(channel_id_or_user, start_date, end_date, limit=10, show_all=False):
    """
    –ó–±–∏—Ä–∞—î –º–µ—Ç–∞–¥–∞–Ω—ñ –≤—ñ–¥–µ–æ –∑ –∫–∞–Ω–∞–ª—É –∞–±–æ –≤—ñ–¥ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é yt_dlp.
    –§—ñ–ª—å—Ç—Ä—É—î –∑–∞ –¥–∞—Ç–æ—é.
    –ü—Ä–∏–º—ñ—Ç–∫–∞: —Ü—è —Ñ—É–Ω–∫—Ü—ñ—è –Ω–∞—Ä–∞–∑—ñ –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º—É –ø–æ—Ç–æ—Ü—ñ UI.
    """
    if not channel_id_or_user:
        st.error("–ù–µ –Ω–∞–¥–∞–Ω–æ ID –∫–∞–Ω–∞–ª—É –∞–±–æ —ñ–º'—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞.")
        return []

    # –§–æ—Ä–º—É–≤–∞–Ω–Ω—è URL –¥–ª—è yt-dlp
    if channel_id_or_user.startswith("UC"):  # –¶–µ ID –∫–∞–Ω–∞–ª—É
        # yt-dlp –º–æ–∂–µ –æ–±—Ä–æ–±–ª—è—Ç–∏ URL –∫–∞–Ω–∞–ª—É, –∞–ª–µ –¥–ª—è –ø–æ–≤–Ω–æ–≥–æ —Å–ø–∏—Å–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—å –º–æ–∂–µ –∑–Ω–∞–¥–æ–±–∏—Ç–∏—Å—è playlists URL
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç–∏, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–∞–≥–∞–ª—å–Ω–∏–π URL –∫–∞–Ω–∞–ª—É.
        # –î–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –ø–ª–µ–π–ª–∏—Å—Ç–∞ "uploads" –∑–∞–∑–≤–∏—á–∞–π –ø–æ—Ç—Ä—ñ–±–µ–Ω API, —â–æ–± –æ—Ç—Ä–∏–º–∞—Ç–∏ ID –ø–ª–µ–π–ª–∏—Å—Ç–∞ (UU...).
        # yt-dlp —Å–ø—Ä–æ–±—É—î –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤—ñ–¥–µ–æ –∑—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ /videos
        url = f"https://www.youtube.com/channel/{channel_id_or_user}/videos"
        st.info(f"–°–ø—Ä–æ–±–∞ –∑–±–æ—Ä—É –≤—ñ–¥–µ–æ –¥–ª—è ID –∫–∞–Ω–∞–ª—É: {channel_id_or_user}. –†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ –±—É—Ç–∏ –Ω–µ–ø–æ–≤–Ω–∏–º –¥–ª—è –≤—Å—ñ—Ö –≤—ñ–¥–µ–æ –∫–∞–Ω–∞–ª—É –±–µ–∑ –ø—Ä—è–º–æ–≥–æ ID –ø–ª–µ–π–ª–∏—Å—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—å.")
    else:  # –¶–µ —ñ–º'—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (–ø—ñ—Å–ª—è @)
        url = f"https://www.youtube.com/@{channel_id_or_user}/videos"

    opts_flat = {
        'ignoreerrors': True,
        'skip_download': True,
        'extract_flat': 'discard_in_playlist',
        'dump_single_json': True,
        'playlistend': limit if not show_all else None,
        'quiet': True,
        'no_warnings': True,
    }

    video_ids = []
    try:
        with yt_dlp.YoutubeDL(opts_flat) as ydl:
            info = ydl.extract_info(url, download=False)
        
        if info and 'entries' in info and info['entries']:
            video_ids = [e['id'] for e in info['entries'] if e and e.get('id')]
        elif info and info.get('id') and not info.get('entries'): # –Ø–∫—â–æ URL –≤–∫–∞–∑—É—î –Ω–∞ –æ–¥–Ω–µ –≤—ñ–¥–µ–æ
             st.warning(f"URL {url} —Å—Ö–æ–∂–∏–π –Ω–∞ URL –æ–¥–Ω–æ–≥–æ –≤—ñ–¥–µ–æ, –∞ –Ω–µ –∫–∞–Ω–∞–ª—É/–ø–ª–µ–π–ª–∏—Å—Ç–∞. –¶—è —Ñ—É–Ω–∫—Ü—ñ—è –æ—á—ñ–∫—É—î URL –∫–∞–Ω–∞–ª—É.")
             # –ú–æ–∂–Ω–∞ –∞–±–æ –ø–æ–≤–µ—Ä–Ω—É—Ç–∏ –ø–æ–º–∏–ª–∫—É, –∞–±–æ —Å–ø—Ä–æ–±—É–≤–∞—Ç–∏ –æ–±—Ä–æ–±–∏—Ç–∏ —Ü–µ –æ–¥–Ω–µ –≤—ñ–¥–µ–æ, 
             # –∞–ª–µ —Ü–µ –≤–∏—Ö–æ–¥–∏—Ç—å –∑–∞ —Ä–∞–º–∫–∏ –ø–æ—á–∞—Ç–∫–æ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó.
             # video_ids = [info['id']] # –Ø–∫—â–æ –≤–∏—Ä—ñ—à–∏–º–æ –æ–±—Ä–æ–±–ª—è—Ç–∏
             return []


    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –Ω–∞ –µ—Ç–∞–ø—ñ flat-–ø–∞—Ä—Å–∏–Ω–≥—É yt_dlp –¥–ª—è {url}: {e}")
        return []

    if not video_ids:
        st.warning(f"–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ ID –≤—ñ–¥–µ–æ –¥–ª—è {url} –Ω–∞ –ø–µ—Ä—à–æ–º—É –µ—Ç–∞–ø—ñ.")
        return []

    opts_det = {
        'ignoreerrors': True, 
        'skip_download': True, 
        'extract_flat': False,
        'quiet': True,
        'no_warnings': True,
    }
    videos = []

    video_ids_to_process = video_ids
    if not show_all and len(video_ids) > limit * 1.5: # –ù–µ–≤–µ–ª–∏–∫–∏–π –±—É—Ñ–µ—Ä, —è–∫—â–æ playlistend –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–≤ —ñ–¥–µ–∞–ª—å–Ω–æ
        video_ids_to_process = video_ids[:int(limit * 1.5)]


    for vid_id in video_ids_to_process:
        if not show_all and len(videos) >= limit:
            break
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π URL –¥–ª—è –≤—ñ–¥–µ–æ
        vurl = f"https://www.youtube.com/watch?v={vid_id}"
        try:
            with yt_dlp.YoutubeDL(opts_det) as ydl:
                vinfo = ydl.extract_info(vurl, download=False)

            if not vinfo:
                continue

            upload_date_str = vinfo.get('upload_date')
            publish_date = None
            if upload_date_str:
                try:
                    publish_date = datetime.strptime(upload_date_str, '%Y%m%d').date()
                except ValueError:
                    publish_date = None

            if show_all or (publish_date and start_date <= publish_date <= end_date):
                videos.append({
                    'title': vinfo.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∏'),
                    'views': vinfo.get('view_count', 0),
                    'likes': vinfo.get('like_count'),
                    'comments_count': vinfo.get('comment_count'),
                    'duration': vinfo.get('duration', 0),
                    'publish_date': publish_date,
                    'thumbnail_url': vinfo.get('thumbnail'),
                    'url': vinfo.get('webpage_url', vurl)
                })
        except Exception as e:
            st.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏ –≤—ñ–¥–µ–æ {vurl}: {e}")
            continue
    return videos


def fetch_comments(video_url, pct_str="100%"):
    """
    –ó–±–∏—Ä–∞—î –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ —á–µ—Ä–µ–∑ YouTube Data API v3.
    –ü–æ–≤–µ—Ä—Ç–∞—î pct_str% –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤, –∑ –ª–∞–π–∫–∞–º–∏ —ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—è–º–∏.
    """
    if not YT_API_KEY:
        st.error("–ù–µ –∑–∞–¥–∞–Ω–∏–π –∫–ª—é—á API YouTube (YOUTUBE_API_KEY) –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤.")
        return []

    video_id_match = re.search(r"(?:v=|youtu\.be/|shorts/|embed/|watch\?v=|\&v=)([\w-]{11})", video_url)
    if not video_id_match:
        if re.match(r"^[\w-]{11}$", video_url): # –Ø–∫—â–æ —Ü–µ –≤–∂–µ ID
            video_id = video_url
        else:
            st.error(f"–ù–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç URL –∞–±–æ ID –≤—ñ–¥–µ–æ –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤: {video_url}")
            return []
    else:
        video_id = video_id_match.group(1)

    try:
        youtube_service = build("youtube", "v3", developerKey=YT_API_KEY)
        comments_data = []
        next_page_token = None
        max_comments_limit = 1000 # –ó–∞–≥–∞–ª—å–Ω–µ –æ–±–º–µ–∂–µ–Ω–Ω—è –Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –æ–¥–Ω–æ–≥–æ –≤—ñ–¥–µ–æ

        while True:
            response = youtube_service.commentThreads().list(
                part="snippet,replies",
                videoId=video_id,
                maxResults=100, # –ú–∞–∫—Å–∏–º—É–º –∑–∞ –æ–¥–∏–Ω –∑–∞–ø–∏—Ç
                pageToken=next_page_token,
                textFormat="plainText"
            ).execute()

            for item in response.get("items", []):
                top_level_comment_snippet = item.get("snippet", {}).get("topLevelComment", {}).get("snippet", {})
                replies_data = item.get("replies", {}).get("comments", []) # –¶–µ –≤–∂–µ —Å–ø–∏—Å–æ–∫ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤-–≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π

                comments_data.append({
                    "text": top_level_comment_snippet.get("textDisplay", ""),
                    "likes": top_level_comment_snippet.get("likeCount", 0),
                    "replies": replies_data # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Å–ø–∏—Å–æ–∫ –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π
                })
                if len(comments_data) >= max_comments_limit:
                    break
            
            if len(comments_data) >= max_comments_limit:
                break

            next_page_token = response.get("nextPageToken")
            if not next_page_token:
                break
        
        # –û–±—Ä–æ–±–∫–∞ –≤—ñ–¥—Å–æ—Ç–∫–∞
        if pct_str != "100%":
            try:
                percentage_to_fetch = float(pct_str.strip('%')) / 100
                num_to_return = int(len(comments_data) * percentage_to_fetch)
                # –ü–µ—Ä–µ–º—ñ—à—É—î–º–æ –ø–µ—Ä–µ–¥ —Ç–∏–º —è–∫ –±—Ä–∞—Ç–∏ –∑—Ä—ñ–∑, —â–æ–± –æ—Ç—Ä–∏–º–∞—Ç–∏ –±—ñ–ª—å—à –≤–∏–ø–∞–¥–∫–æ–≤—É –≤–∏–±—ñ—Ä–∫—É
                random.shuffle(comments_data) 
                return comments_data[:num_to_return]
            except ValueError:
                st.warning(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –≤—ñ–¥—Å–æ—Ç–∫–∞: {pct_str}. –ü–æ–≤–µ—Ä—Ç–∞—é –≤—Å—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ.")
        
        return comments_data
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ —á–µ—Ä–µ–∑ YouTube API: {e}")
        return []


def gpt_sentiment_analysis(comments_texts_list, model="gpt-3.5-turbo"):
    if not client:
        st.error("–ö–ª—ñ—î–Ω—Ç OpenAI –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π (–ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ API –∫–ª—é—á).")
        return {"positive": 0, "neutral": 0, "negative": 0, "error": "OpenAI client not initialized."}

    if not comments_texts_list:
        return {"positive": 0, "neutral": 0, "negative": 0, "error": "–ù–µ–º–∞—î —Ç–µ–∫—Å—Ç—ñ–≤ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É."}

    clean_comments_list = [c for c in comments_texts_list if isinstance(c, str) and c.strip()]
    if not clean_comments_list:
        return {"positive": 0, "neutral": 0, "negative": 0, "error": "–ü—ñ—Å–ª—è –æ—á–∏—Å—Ç–∫–∏ –Ω–µ –∑–∞–ª–∏—à–∏–ª–æ—Å—è –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É."}

    sample_comments = clean_comments_list[:100] # –û–±–º–µ–∂—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø–∏—Ç—É

    prompt_text = f"""
–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –Ω–∞—Å—Ç—É–ø–Ω—ñ —é—Ç—É–±-–∫–æ–º–µ–Ω—Ç–∞—Ä—ñ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é. –ü–æ—Ä–∞—Ö—É–π —Ç–∞ –ø–æ–≤–µ—Ä–Ω–∏ –ø—Ä–∏–±–ª–∏–∑–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å:
- –ø–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö (positive)
- –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∏—Ö (neutral)
- –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö (negative)

–ü–æ–≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON –∑ –∫–ª—é—á–∞–º–∏ "positive", "neutral", "negative". –ù–∞–ø—Ä–∏–∫–ª–∞–¥:
{{
  "positive": X,
  "neutral": Y,
  "negative": Z
}}

–ö–æ–º–µ–Ω—Ç–∞—Ä—ñ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É:
{chr(10).join(sample_comments)}
""".strip()

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt_text}],
            temperature=0.2, # –ó–º–µ–Ω—à–µ–Ω–æ –¥–ª—è –±—ñ–ª—å—à –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –ø—ñ–¥—Ä–∞—Ö—É–Ω–∫—É
            max_tokens=150, # –¢—Ä–æ—Ö–∏ –∑–±—ñ–ª—å—à–µ–Ω–æ –ø—Ä–æ –≤—Å—è–∫ –≤–∏–ø–∞–¥–æ–∫ –¥–ª—è JSON
        )
        api_response_text = response.choices[0].message.content.strip()

        try:
            # –°–ø—Ä–æ–±–∞ –≤–∏–¥–∞–ª–∏—Ç–∏ –º–æ–∂–ª–∏–≤—ñ ```json ... ``` –æ–±–≥–æ—Ä—Ç–∫–∏
            if api_response_text.startswith("```json"):
                api_response_text = api_response_text[7:]
            if api_response_text.endswith("```"):
                api_response_text = api_response_text[:-3]
            
            sentiment_results = json.loads(api_response_text)
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –∫–ª—é—á—ñ–≤ —Ç–∞ —ó—Ö —Ç–∏–ø—ñ–≤
            if not all(k in sentiment_results and isinstance(sentiment_results[k], int) for k in ["positive", "neutral", "negative"]):
                st.warning(f"GPT –ø–æ–≤–µ—Ä–Ω—É–≤ JSON, –∞–ª–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–±–æ —Ç–∏–ø–∏ –¥–∞–Ω–∏—Ö –Ω–µ–≤—ñ—Ä–Ω—ñ: {api_response_text}")
                return {"positive": 0, "neutral": 0, "negative": 0, "error": "Invalid JSON structure or data types from GPT."}
            return sentiment_results
        except json.JSONDecodeError:
            st.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø–∞—Ä—Å–∏—Ç–∏ JSON –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ GPT –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ: {api_response_text}")
            # –°–ø—Ä–æ–±—É—î–º–æ —Å—Ç–∞—Ä–∏–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥—É —è–∫ –∑–∞–ø–∞—Å–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç, —è–∫—â–æ JSON –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–≤
            st.info("–°–ø—Ä–æ–±–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –º–µ—Ç–æ–¥—É –ø–∞—Ä—Å–∏–Ω–≥—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ...")
            sentiment_results_fallback = {"positive": 0, "neutral": 0, "negative": 0}
            for line_text in api_response_text.lower().splitlines():
                line_text = line_text.strip()
                if "positive:" in line_text or '"positive":' in line_text:
                    found_numbers = re.findall(r"\d+", line_text)
                    if found_numbers: sentiment_results_fallback["positive"] = int(found_numbers[0])
                elif "neutral:" in line_text or '"neutral":' in line_text:
                    found_numbers = re.findall(r"\d+", line_text)
                    if found_numbers: sentiment_results_fallback["neutral"] = int(found_numbers[0])
                elif "negative:" in line_text or '"negative":' in line_text:
                    found_numbers = re.findall(r"\d+", line_text)
                    if found_numbers: sentiment_results_fallback["negative"] = int(found_numbers[0])
            
            if sum(sentiment_results_fallback.values()) > 0:
                 st.success("–†–µ–∑–µ—Ä–≤–Ω–∏–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ —Å–ø—Ä–∞—Ü—é–≤–∞–≤.")
                 return sentiment_results_fallback
            else:
                 st.error("–†–µ–∑–µ—Ä–≤–Ω–∏–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ —Ç–∞–∫–æ–∂ –Ω–µ –¥–∞–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É.")
                 return {"positive": 0, "neutral": 0, "negative": 0, "error": f"GPT response not parsable as JSON or text: {api_response_text}"}


    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ GPT –ø—Ä–∏ –∞–Ω–∞–ª—ñ–∑—ñ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ: {e}")
        return {"positive": 0, "neutral": 0, "negative": 0, "error": str(e)}


def gpt_comment_summary(comments_texts_list, model="gpt-3.5-turbo"):
    if not client:
        st.error("–ö–ª—ñ—î–Ω—Ç OpenAI –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π (–ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ API –∫–ª—é—á).")
        return "–ö–ª—ñ—î–Ω—Ç OpenAI –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π."

    if not comments_texts_list:
        return "–ù–µ–º–∞—î –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—É."

    clean_comments_list = [c for c in comments_texts_list if isinstance(c, str) and c.strip()]
    if not clean_comments_list:
        return "–ü—ñ—Å–ª—è –æ—á–∏—Å—Ç–∫–∏ –Ω–µ –∑–∞–ª–∏—à–∏–ª–æ—Å—è –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—É."

    # –ë–µ—Ä–µ–º–æ –≤–∏–±—ñ—Ä–∫—É, –∞–ª–µ —è–∫—â–æ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –º–∞–ª–æ, –±–µ—Ä–µ–º–æ –≤—Å—ñ
    sample_size = min(100, len(clean_comments_list))
    sample_for_summary = random.sample(clean_comments_list, sample_size)


    prompt_text = f"""
–¢–æ–±—ñ –Ω–∞–¥–∞–Ω–æ –≤–∏–±—ñ—Ä–∫—É –∑ {sample_size} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –ø—ñ–¥ –≤—ñ–¥–µ–æ –∑ YouTube —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é.

1. –ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –∞–Ω–∞–ª—ñ–∑ –Ω–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à–∏—Ö —Ç–µ–º –∞–±–æ –Ω–∞—Å—Ç—Ä–æ—ó–≤ —É —Ü–∏—Ö –∫–æ–º–µ–Ω—Ç–∞—Ä—è—Ö (2-3 —Ä–µ—á–µ–Ω–Ω—è).
2. –£–∑–∞–≥–∞–ª—å–Ω–∏ (–ø–æ 1-2 —Ä–µ—á–µ–Ω–Ω—è –Ω–∞ –∫–æ–∂–µ–Ω –ø—É–Ω–∫—Ç):
   - –©–æ –Ω–∞–π–±—ñ–ª—å—à–µ —Å–ø–æ–¥–æ–±–∞–ª–æ—Å—å –≥–ª—è–¥–∞—á–∞–º (—è–∫—â–æ —Ü–µ –≤–∏–¥–Ω–æ –∑ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤)?
   - –©–æ –∑–∞–ª–∏—à–∏–ª–æ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–µ –≤—Ä–∞–∂–µ–Ω–Ω—è –∞–±–æ –±—É–ª–æ –º–µ–Ω—à –æ–±–≥–æ–≤–æ—Ä—é–≤–∞–Ω–∏–º?
   - –©–æ –≤–∏–∫–ª–∏–∫–∞–ª–æ –Ω–µ–≥–∞—Ç–∏–≤ —á–∏ –∫—Ä–∏—Ç–∏–∫—É (—è–∫—â–æ —î)?
3. –ó—Ä–æ–±–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –≤–∏—Å–Ω–æ–≤–æ–∫ (1-2 —Ä–µ—á–µ–Ω–Ω—è) –ø—Ä–æ –∑–∞–≥–∞–ª—å–Ω–µ –≤—Ä–∞–∂–µ–Ω–Ω—è –∞—É–¥–∏—Ç–æ—Ä—ñ—ó –≤—ñ–¥ –≤—ñ–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ü–∏—Ö –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤.

–ë—É–¥—å –ª–∞—Å–∫–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä—É–π –≤—ñ–¥–ø–æ–≤—ñ–¥—å —á—ñ—Ç–∫–æ.

–ö–æ–º–µ–Ω—Ç–∞—Ä—ñ:
{chr(10).join(sample_for_summary)}
""".strip()

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt_text}],
            temperature=0.7,
            max_tokens=800,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ GPT –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø—ñ–¥—Å—É–º–∫—É –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤: {e}")
        return f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ GPT: {e}"


def format_duration(seconds_total):
    """–§–æ—Ä–º–∞—Ç—É—î —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∑ —Å–µ–∫—É–Ω–¥ —É HH:MM:SS."""
    if not isinstance(seconds_total, (int, float)) or seconds_total < 0:
        return "00:00:00"
    h = int(seconds_total // 3600)
    m = int((seconds_total % 3600) // 60)
    s = int(seconds_total % 60)
    return f"{h:02}:{m:02}:{s:02}"


# --- –û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–∏ (—Ç—ñ–ª—å–∫–∏ "–ê–Ω–∞–ª—ñ–∑ –≤—ñ–¥–µ–æ") ---

video_url_input = st.text_input(
    "URL –≤—ñ–¥–µ–æ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É:",
    placeholder="–í—Å—Ç–∞–≤—Ç–µ URL YouTube –≤—ñ–¥–µ–æ...",
    key="main_video_url_input"
)

comments_percentage_options = {"–í—Å—ñ": "100%", "50%": "50%", "25%": "25%", "10%": "10%"}
selected_display_percentage = st.selectbox(
    "–Ø–∫—É —á–∞—Å—Ç–∫—É –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ (–≤–∏–ø–∞–¥–∫–æ–≤–∞ –≤–∏–±—ñ—Ä–∫–∞):",
    list(comments_percentage_options.keys()),
    index=0, 
    key="comments_percentage_selector"
)
percentage_to_fetch_str = comments_percentage_options[selected_display_percentage]

if st.button("üöÄ –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –≤—ñ–¥–µ–æ", key="analyze_this_video_button"):
    if not video_url_input:
        st.error("–ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å URL –≤—ñ–¥–µ–æ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.")
    else:
        # 1. –û—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –≤—ñ–¥–µ–æ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é yt_dlp
        with st.spinner("–ó–±—ñ—Ä –¥–∞–Ω–∏—Ö –ø—Ä–æ –≤—ñ–¥–µ–æ..."):
            video_details = None
            try:
                ydl_opts_video = {
                    'quiet': True,
                    'no_warnings': True,
                    'skip_download': True,
                    'ignoreerrors': True,
                    'extract_flat': False, # –ü–æ—Ç—Ä—ñ–±–Ω—ñ –ø–æ–≤–Ω—ñ –º–µ—Ç–∞–¥–∞–Ω—ñ –¥–ª—è –æ–¥–Ω–æ–≥–æ –≤—ñ–¥–µ–æ
                }
                with yt_dlp.YoutubeDL(ydl_opts_video) as ydl:
                    video_details = ydl.extract_info(video_url_input, download=False)
            except Exception as e:
                st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ –¥–∞–Ω–∏—Ö –≤—ñ–¥–µ–æ —á–µ—Ä–µ–∑ yt_dlp: {e}")
                video_details = None # –ü–µ—Ä–µ–∫–æ–Ω—É—î–º–æ—Å—å, —â–æ video_details None —É –≤–∏–ø–∞–¥–∫—É –ø–æ–º–∏–ª–∫–∏

        if not video_details:
            st.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –¥–ª—è –≤—ñ–¥–µ–æ –∑–∞ URL: {video_url_input}")
        else:
            st.subheader(f"–ê–Ω–∞–ª—ñ–∑ –≤—ñ–¥–µ–æ: {video_details.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∏')}")

            col_thumb, col_info = st.columns([1, 3])
            with col_thumb:
                if video_details.get('thumbnail'):
                    st.image(video_details.get('thumbnail'), width=240, caption="–û–±–∫–ª–∞–¥–∏–Ω–∫–∞ –≤—ñ–¥–µ–æ")
                else:
                    st.write("üñºÔ∏è (–Ω–µ–º–∞—î –æ–±–∫–ª–∞–¥–∏–Ω–∫–∏)")

            with col_info:
                st.markdown(f"**–ù–∞–∑–≤–∞:** {video_details.get('title', 'N/A')}")
                st.markdown(f"**–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å:** {format_duration(video_details.get('duration', 0))}")
                
                view_count = video_details.get('view_count')
                st.markdown(f"**–ü–µ—Ä–µ–≥–ª—è–¥–∏:** {view_count:,}" if isinstance(view_count, int) else "N/A")
                
                likes_count = video_details.get('like_count')
                st.markdown(f"**–õ–∞–π–∫–∏:** {likes_count:,}" if isinstance(likes_count, int) else "N/A (–ø—Ä–∏—Ö–æ–≤–∞–Ω–æ –∞–±–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ)")

                comment_count_overall = video_details.get('comment_count') # –¶–µ –º–æ–∂–µ –±—É—Ç–∏ –∑–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å, —è–∫—É –ø–æ–≤–µ—Ä–Ω—É–≤ yt-dlp
                st.markdown(f"**–ö–æ–º–µ–Ω—Ç–∞—Ä—ñ (–∑–∞ –¥–∞–Ω–∏–º–∏ yt-dlp):** {comment_count_overall:,}" if isinstance(comment_count_overall, int) else "N/A")

                upload_date_str = video_details.get('upload_date')
                if upload_date_str:
                    try:
                        publish_date_dt = datetime.strptime(upload_date_str, '%Y%m%d').date()
                        st.markdown(f"**–î–∞—Ç–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó:** {publish_date_dt.strftime('%d.%m.%Y')}")
                    except ValueError:
                        st.markdown(f"**–î–∞—Ç–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó:** {upload_date_str} (–Ω–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø–∞—Ä—Å–∏—Ç–∏ —Ñ–æ—Ä–º–∞—Ç)")
                else:
                    st.markdown("**–î–∞—Ç–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó:** N/A")

            st.markdown("---")
            st.subheader("üìà –ê–Ω–∞–ª—ñ–∑ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–æ –≤—ñ–¥–µ–æ")

            with st.spinner(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –∞–Ω–∞–ª—ñ–∑ ~{selected_display_percentage} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤..."):
                # –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ —Ç—É—Ç: pct_str=percentage_to_fetch_str
                fetched_comments_data = fetch_comments(video_url_input, pct_str=percentage_to_fetch_str)

            if not fetched_comments_data:
                st.info("–ö–æ–º–µ–Ω—Ç–∞—Ä—ñ –¥–æ —Ü—å–æ–≥–æ –≤—ñ–¥–µ–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, —ó—Ö –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏, –∞–±–æ –æ–±—Ä–∞–Ω–æ 0%.")
            else:
                st.info(f"–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –ø—Ä–∏–±–ª–∏–∑–Ω–æ {len(fetched_comments_data)} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤.")
                comment_texts_for_gpt = [
                    comment.get("text", "") for comment in fetched_comments_data
                    if isinstance(comment, dict) and isinstance(comment.get("text"), str) and comment.get("text").strip()
                ]

                if not comment_texts_for_gpt:
                    st.warning("–•–æ—á–∞ –¥–∞–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –±—É–ª–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ, —Ç–µ–∫—Å—Ç–æ–≤–∏–π –≤–º—ñ—Å—Ç –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –≤—ñ–¥—Å—É—Ç–Ω—ñ–π –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π.")
                else:
                    st.markdown("##### –¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ (–∑–∞ –≤–µ—Ä—Å—ñ—î—é GPT):")
                    sentiment_gpt_result = gpt_sentiment_analysis(comment_texts_for_gpt)

                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —î –ø–æ–º–∏–ª–∫–∞, —ñ —á–∏ —î —Ö–æ—á —è–∫—ñ—Å—å –¥–∞–Ω—ñ
                    if "error" not in sentiment_gpt_result or sum(v for k, v in sentiment_gpt_result.items() if k != "error" and isinstance(v, int)) > 0:
                        # –í–∏–∫–ª—é—á–∞—î–º–æ 'error' –∑ –ø—ñ–¥—Ä–∞—Ö—É–Ω–∫—É total_valid_sentiments
                        total_valid_sentiments = sum(v for k, v in sentiment_gpt_result.items() if k != "error" and isinstance(v, int))
                        if total_valid_sentiments == 0 and "error" not in sentiment_gpt_result : # –Ø–∫—â–æ GPT –ø–æ–≤–µ—Ä–Ω—É–≤ 0 –¥–ª—è –≤—Å—ñ—Ö, –∞–ª–µ –±–µ–∑ –ø–æ–º–∏–ª–∫–∏
                             st.info("GPT –æ—Ü—ñ–Ω–∏–≤ —É—Å—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ —è–∫ —Ç–∞–∫—ñ, —â–æ –Ω–µ –º–∞—é—Ç—å —á—ñ—Ç–∫–æ—ó —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ, –∞–±–æ –≤–∏–±—ñ—Ä–∫–∞ –±—É–ª–∞ –∑–∞–º–∞–ª–∞.")
                        elif total_valid_sentiments > 0:
                            pos_pct = (sentiment_gpt_result.get('positive', 0) / total_valid_sentiments) * 100
                            neu_pct = (sentiment_gpt_result.get('neutral', 0) / total_valid_sentiments) * 100
                            neg_pct = (sentiment_gpt_result.get('negative', 0) / total_valid_sentiments) * 100

                            bar_len = 20
                            pos_bar_len = int(bar_len * pos_pct / 100)
                            neu_bar_len = int(bar_len * neu_pct / 100)
                            neg_bar_len = max(0, bar_len - pos_bar_len - neu_bar_len) # –ó–∞–±–µ–∑–ø–µ—á—É—î–º–æ, —â–æ–± —Å—É–º–∞ –Ω–µ –ø–µ—Ä–µ–≤–∏—â—É–≤–∞–ª–∞ bar_len

                            sentiment_display_bar = "üü©" * pos_bar_len + "üü®" * neu_bar_len + "üü•" * neg_bar_len
                            st.markdown(f"{sentiment_display_bar}  –ü–æ–∑–∏—Ç–∏–≤–Ω—ñ: {pos_pct:.0f}% | –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ñ: {neu_pct:.0f}% | –ù–µ–≥–∞—Ç–∏–≤–Ω—ñ: {neg_pct:.0f}%")
                        
                        if sentiment_gpt_result.get("error"): # –Ø–∫—â–æ —î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫—É, –ø–æ–∫–∞–∑—É—î–º–æ –π–æ–≥–æ
                            st.caption(f"–ü—Ä–∏–º—ñ—Ç–∫–∞ —â–æ–¥–æ –∞–Ω–∞–ª—ñ–∑—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ: {sentiment_gpt_result['error']}")
                    
                    else: # –Ø–∫—â–æ —î –ø–æ–º–∏–ª–∫–∞ —ñ –Ω–µ–º–∞—î –¥–∞–Ω–∏—Ö
                        st.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –∞–Ω–∞–ª—ñ–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ –≤—ñ–¥ GPT. {sentiment_gpt_result.get('error', '–ü–æ–≤–µ—Ä–Ω—É—Ç–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.')}")
                    
                    st.markdown("##### –ó–∞–≥–∞–ª—å–Ω–∏–π –ø—ñ–¥—Å—É–º–æ–∫ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ (–∑–∞ –≤–µ—Ä—Å—ñ—î—é GPT):")
                    with st.spinner("GPT –≥–µ–Ω–µ—Ä—É—î –ø—ñ–¥—Å—É–º–æ–∫ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤..."):
                        summary_from_gpt = gpt_comment_summary(comment_texts_for_gpt)
                    st.markdown(summary_from_gpt)

                    st.markdown("##### üî• –¢–æ–ø-10 –Ω–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à–∏—Ö –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ (–∑–∞ –ª–∞–π–∫–∞–º–∏):")
                    comments_with_likes = [c for c in fetched_comments_data if isinstance(c.get('likes'), int)]

                    if not comments_with_likes:
                        st.info("–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—Ä–æ –ª–∞–π–∫–∏ –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–æ–ø—É.")
                    else:
                        top_10_comments = sorted(comments_with_likes, key=lambda x: x['likes'], reverse=True)[:10]
                        for i, comment_detail in enumerate(top_10_comments):
                            st.markdown(f"---\n**{i + 1}.** üëç {comment_detail['likes']:,} –ª–∞–π–∫—ñ–≤")
                            st.markdown(f"> {comment_detail['text']}")

                            replies_list = comment_detail.get("replies", []) # replies_list —Ç–µ–ø–µ—Ä —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–Ω–∏–∫—ñ–≤ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤-–≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π
                            if replies_list:
                                # –§—ñ–ª—å—Ç—Ä—É—î–º–æ —Ç–∞ —Å–æ—Ä—Ç—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                                valid_replies_list = [
                                    r for r in replies_list 
                                    if isinstance(r, dict) and 
                                       isinstance(r.get("snippet", {}).get("likeCount"), int) and
                                       r.get("snippet", {}).get("textDisplay") # –ü–µ—Ä–µ–∫–æ–Ω—É—î–º–æ—Å—å, —â–æ —î —Ç–µ–∫—Å—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                                ]
                                sorted_replies_list = sorted(
                                    valid_replies_list,
                                    key=lambda r_item: r_item["snippet"]["likeCount"],
                                    reverse=True
                                )[:3] # –û–±–º–µ–∂–µ–Ω–Ω—è –Ω–∞ 3 –Ω–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ

                                if sorted_replies_list:
                                    with st.expander(f"üí¨ –ü–æ–∫–∞–∑–∞—Ç–∏ –¥–æ {len(sorted_replies_list)} –Ω–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à–∏—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π"):
                                        for reply_item in sorted_replies_list:
                                            reply_snippet_data = reply_item.get("snippet", {})
                                            st.markdown(
                                                f"&nbsp;&nbsp;‚Ü≥ {reply_snippet_data.get('textDisplay', '')}  _(üëç {reply_snippet_data.get('likeCount', 0):,})_"
                                            )
