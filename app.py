import os
import re
import streamlit as st
from datetime import date, datetime
import yt_dlp
import pandas as pd
# import random # –í–∏–¥–∞–ª–µ–Ω–æ, –æ—Å–∫—ñ–ª—å–∫–∏ gpt_comment_summary, —â–æ –π–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤, –≤–∏–¥–∞–ª–µ–Ω–æ –∑ —Ü—å–æ–≥–æ –≤–∞—Ä—ñ–∞–Ω—Ç—É
from googleapiclient.discovery import build
from openai import OpenAI

# nltk —Ç–∞ SentimentIntensityAnalyzer –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ, —è–∫—â–æ sentiment_analysis –≤–∏–¥–∞–ª–µ–Ω–æ
# sklearn —Ç–∞ matplotlib –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è

# --- –ö–ª—é—á—ñ API (—Ç–µ–ø–µ—Ä –∑—ñ Streamlit Secrets) ---
# –ü–µ—Ä–µ–¥–±–∞—á–∞—î—Ç—å—Å—è, —â–æ –≤ Streamlit Cloud —Ç–∏ —Å—Ç–≤–æ—Ä–∏—à Secrets –∑ —Ç–∞–∫–∏–º–∏ –∫–ª—é—á–∞–º–∏:
# OPENAI_API_KEY = "sk-..."
# YOUTUBE_API_KEY = "AIzaSy..."

OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY")
YT_API_KEY = st.secrets.get("YOUTUBE_API_KEY")

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª—ñ—î–Ω—Ç–∞ OpenAI
if not OPENAI_API_KEY:
    st.error("–ö–ª—é—á OpenAI API (OPENAI_API_KEY) –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É Streamlit Secrets. –ë—É–¥—å –ª–∞—Å–∫–∞, –¥–æ–¥–∞–π—Ç–µ –π–æ–≥–æ.")
    # –ú–æ–∂–Ω–∞ –∑—É–ø–∏–Ω–∏—Ç–∏ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è, —è–∫—â–æ –∫–ª—é—á –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ, –∞–±–æ –¥–µ—è–∫—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –Ω–µ –±—É–¥—É—Ç—å –ø—Ä–∞—Ü—é–≤–∞—Ç–∏
    # st.stop()
    client = None  # –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ –∫–ª—ñ—î–Ω—Ç–∞ –≤ None, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø–æ–º–∏–ª–æ–∫ –¥–∞–ª—ñ
else:
    client = OpenAI(api_key=OPENAI_API_KEY)

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–ª—é—á–∞ YouTube Data API
if not YT_API_KEY:
    # –ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è –±—É–¥–µ –≤–∏–≤–µ–¥–µ–Ω–µ –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ–π, —è–∫—ñ –π–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å,
    # –∞–±–æ –º–æ–∂–Ω–∞ –≤–∏–≤–µ—Å—Ç–∏ —Ç—É—Ç –≥–ª–æ–±–∞–ª—å–Ω–µ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è.
    st.warning(
        "–ö–ª—é—á YouTube Data API (YOUTUBE_API_KEY) –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É Streamlit Secrets. –§—É–Ω–∫—Ü—ñ—ó, —â–æ –π–æ–≥–æ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å, –º–æ–∂—É—Ç—å –Ω–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏.")

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏
st.set_page_config(page_title="YouTube Analytics Agent", layout="wide")
st.title("YouTube Analytics Agent")
st.markdown(
    """
    –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π –∞–≥–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É YouTube-–∫–∞–Ω–∞–ª—ñ–≤.
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –±—ñ—á–Ω—É –ø–∞–Ω–µ–ª—å –¥–ª—è –Ω–∞–≤—ñ–≥–∞—Ü—ñ—ó –º—ñ–∂ —Å—Ç–æ—Ä—ñ–Ω–∫–∞–º–∏.
    """
)


# --- –§—É–Ω–∫—Ü—ñ—ó ---

def extract_channel_id(url):
    """–í–∏—Ç—è–≥—É—î ID –∫–∞–Ω–∞–ª—É –∑ URL."""
    match = re.search(r"(?:https?://)?(?:www\.)?youtube\.com/@([^/?]+)", url)
    if match:
        return match.group(1)
    # –î–æ–¥–∞–º–æ –æ–±—Ä–æ–±–∫—É URL –∫–∞–Ω–∞–ª—É —Ç–∏–ø—É /channel/UC...
    match_channel = re.search(r"(?:https?://)?(?:www\.)?youtube\.com/channel/([^/?]+)", url)
    if match_channel:
        return match_channel.group(1)  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ ID –∫–∞–Ω–∞–ª—É, –∞ –Ω–µ —ñ–º'—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    return None


def fetch_video_metadata(channel_id_or_user, start_date, end_date, limit=10, show_all=False):
    """
    –ó–±–∏—Ä–∞—î –º–µ—Ç–∞–¥–∞–Ω—ñ –≤—ñ–¥–µ–æ –∑ –∫–∞–Ω–∞–ª—É –∞–±–æ –≤—ñ–¥ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é yt_dlp.
    –§—ñ–ª—å—Ç—Ä—É—î –∑–∞ –¥–∞—Ç–æ—é.
    """
    # yt_dlp –∫—Ä–∞—â–µ –ø—Ä–∞—Ü—é—î –∑ URL, —â–æ –≤–∫–∞–∑—É—î –Ω–∞ –ø–ª–µ–π–ª–∏—Å—Ç –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—å –∞–±–æ —Å—Ç–æ—Ä—ñ–Ω–∫—É –≤—ñ–¥–µ–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞/–∫–∞–Ω–∞–ª—É
    # –Ø–∫—â–æ —Ü–µ ID –∫–∞–Ω–∞–ª—É (–∑–∞–∑–≤–∏—á–∞–π –ø–æ—á–∏–Ω–∞—î—Ç—å—Å—è –∑ UC), —Ñ–æ—Ä–º—É—î–º–æ URL –ø–ª–µ–π–ª–∏—Å—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—å
    if channel_id_or_user.startswith("UC"):
        # –î–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –ø–ª–µ–π–ª–∏—Å—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—å –∑–∞ ID –∫–∞–Ω–∞–ª—É –ø–æ—Ç—Ä—ñ–±–µ–Ω YouTube Data API
        # yt_dlp –Ω–∞–ø—Ä—è–º—É –Ω–µ –º–æ–∂–µ –æ—Ç—Ä–∏–º–∞—Ç–∏ –ø–ª–µ–π–ª–∏—Å—Ç –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—å –ª–∏—à–µ –∑–∞ ID –∫–∞–Ω–∞–ª—É.
        # –ü—Ä–æ—Å—Ç—ñ—à–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç –¥–ª—è yt_dlp - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ URL —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –≤—ñ–¥–µ–æ –∫–∞–Ω–∞–ª—É.
        # –û–¥–Ω–∞–∫, –Ω–∞–π–Ω–∞–¥—ñ–π–Ω—ñ—à–µ –¥–ª—è yt_dlp - —Ü–µ URL —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –≤—ñ–¥–µ–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (@username/videos)
        # –∞–±–æ –ø—Ä—è–º–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –ø–ª–µ–π–ª–∏—Å—Ç.
        # –û—Å–∫—ñ–ª—å–∫–∏ extract_channel_id –ø–æ–≤–µ—Ä—Ç–∞—î —ñ–º'—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –¥–ª—è @-–ø–æ—Å–∏–ª–∞–Ω—å,
        # —ñ ID –¥–ª—è /channel/-–ø–æ—Å–∏–ª–∞–Ω—å, –Ω–∞–º –ø–æ—Ç—Ä—ñ–±–Ω–∞ —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∞ –ª–æ–≥—ñ–∫–∞.

        # –Ø–∫—â–æ —Ü–µ —ñ–º'—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (–Ω–µ –ø–æ—á–∏–Ω–∞—î—Ç—å—Å—è –∑ UC)
        if not channel_id_or_user.startswith("UC"):
            url = f"https://www.youtube.com/@{channel_id_or_user}/videos"
        else:  # –Ø–∫—â–æ —Ü–µ ID –∫–∞–Ω–∞–ª—É (UC...)
            # yt_dlp –Ω–µ –º–æ–∂–µ –Ω–∞–ø—Ä—è–º—É –≤–∑—è—Ç–∏ –≤—Å—ñ –≤—ñ–¥–µ–æ –ª–∏—à–µ –∑–∞ ID –∫–∞–Ω–∞–ª—É –±–µ–∑ API
            # –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è playlist ID. –¢–æ–º—É —Ç—É—Ç –º–æ–∂–µ –±—É—Ç–∏ –æ–±–º–µ–∂–µ–Ω–Ω—è.
            # –°–ø—Ä–æ–±—É—î–º–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ URL –∫–∞–Ω–∞–ª—É, —Ö–æ—á–∞ —Ü–µ –º–µ–Ω—à –Ω–∞–¥—ñ–π–Ω–æ –¥–ª—è yt_dlp –±–µ–∑ API.
            st.warning(
                f"–ó–±—ñ—Ä –≤—ñ–¥–µ–æ –∑–∞ ID –∫–∞–Ω–∞–ª—É ({channel_id_or_user}) —á–µ—Ä–µ–∑ yt_dlp –º–æ–∂–µ –±—É—Ç–∏ –Ω–µ–ø–æ–≤–Ω–∏–º –±–µ–∑ –ø—Ä—è–º–æ–≥–æ ID –ø–ª–µ–π–ª–∏—Å—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—å. –†–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ URL –∑ @username.")
            url = f"https://www.youtube.com/@...{channel_id_or_user}/videos"

    else:  # –Ø–∫—â–æ —Ü–µ —ñ–º'—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (–Ω–µ UC...)
        url = f"https://www.youtube.com/@{channel_id_or_user}/videos"

    opts_flat = {
        'ignoreerrors': True,
        'skip_download': True,
        'extract_flat': 'discard_in_playlist',  # 'discard_in_playlist' –∞–±–æ True –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –ª–∏—à–µ ID
        'dump_single_json': True,
        'playlistend': limit if not show_all else None  # –û–±–º–µ–∂–µ–Ω–Ω—è, —è–∫—â–æ –Ω–µ –ø–æ–∫–∞–∑—É—î–º–æ –≤—Å—ñ
    }

    video_ids = []
    try:
        with yt_dlp.YoutubeDL(opts_flat) as ydl:
            info = ydl.extract_info(url, download=False)

        # yt_dlp –º–æ–∂–µ –ø–æ–≤–µ—Ä—Ç–∞—Ç–∏ 'entries' –¥–ª—è –ø–ª–µ–π–ª–∏—Å—Ç—ñ–≤/–∫–∞–Ω–∞–ª—ñ–≤
        entries = info.get('entries')
        if entries:  # –Ø–∫—â–æ —Ü–µ —Å–ø–∏—Å–æ–∫ –≤—ñ–¥–µ–æ (–∫–∞–Ω–∞–ª/–ø–ª–µ–π–ª–∏—Å—Ç)
            video_ids = [e['id'] for e in entries if e and e.get('id')]
        elif info and info.get('id') and info.get(
                'entries') is None:  # –Ø–∫—â–æ —Ü–µ –æ–¥–Ω–µ –≤—ñ–¥–µ–æ (–º–∞–ª–æ–π–º–æ–≤—ñ—Ä–Ω–æ –¥–ª—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∫–∞–Ω–∞–ª—É)
            video_ids = [info['id']]

    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –Ω–∞ –µ—Ç–∞–ø—ñ flat-–ø–∞—Ä—Å–∏–Ω–≥—É yt_dlp –¥–ª—è {url}: {e}")
        return []

    if not video_ids:
        st.warning(f"–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ ID –≤—ñ–¥–µ–æ –¥–ª—è {url} –Ω–∞ –ø–µ—Ä—à–æ–º—É –µ—Ç–∞–ø—ñ.")
        return []

    # –ï—Ç–∞–ø 2: –¥–µ—Ç–∞–ª—å–Ω–∏–π –∑–±—ñ—Ä –º–µ—Ç–∞–¥–∞–Ω–∏—Ö —Ç–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–∞ –¥–∞—Ç–∞–º–∏
    opts_det = {'ignoreerrors': True, 'skip_download': True, 'extract_flat': False}  # –¢–µ–ø–µ—Ä extract_flat: False
    videos = []

    # –û–±–º–µ–∂—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å ID, —è–∫—â–æ —ó—Ö –∑–∞–±–∞–≥–∞—Ç–æ, —â–æ–± –Ω–µ –ø–µ—Ä–µ–≤–∏—â–∏—Ç–∏ –ª—ñ–º—ñ—Ç–∏/—á–∞—Å
    # –¶–µ –æ—Å–æ–±–ª–∏–≤–æ –≤–∞–∂–ª–∏–≤–æ, —è–∫—â–æ show_all=True —ñ limit –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–≤ –Ω–∞ –ø–µ—Ä—à–æ–º—É –µ—Ç–∞–ø—ñ
    if not show_all and len(video_ids) > limit * 2:  # –ù–µ–≤–µ–ª–∏–∫–∏–π –±—É—Ñ–µ—Ä
        video_ids_to_process = video_ids[:limit * 2]
    else:
        video_ids_to_process = video_ids

    for vid_id in video_ids_to_process:
        if not show_all and len(videos) >= limit:  # –Ø–∫—â–æ –≤–∂–µ –Ω–∞–±—Ä–∞–ª–∏ –ø–æ—Ç—Ä—ñ–±–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å
            break
        vurl = f"https://youtu.be/{vid_id}"
        try:
            with yt_dlp.YoutubeDL(opts_det) as ydl:
                vinfo = ydl.extract_info(vurl, download=False)

            if not vinfo:  # –Ø–∫—â–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ ID –Ω—ñ—á–æ–≥–æ –Ω–µ –ø–æ–≤–µ—Ä–Ω—É—Ç–æ
                continue

            upload_date_str = vinfo.get('upload_date')  # –§–æ—Ä–º–∞—Ç YYYYMMDD
            publish_date = None
            if upload_date_str:
                try:
                    publish_date = datetime.strptime(upload_date_str, '%Y%m%d').date()
                except ValueError:
                    publish_date = None  # –ó–∞–ª–∏—à–∞—î–º–æ None, —è–∫—â–æ –¥–∞—Ç–∞ –Ω–µ –ø–∞—Ä—Å–∏—Ç—å—Å—è

            if show_all or (publish_date and start_date <= publish_date <= end_date):
                videos.append({
                    'title': vinfo.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∏'),
                    'views': vinfo.get('view_count', 0),
                    'likes': vinfo.get('like_count'),  # –ú–æ–∂–µ –±—É—Ç–∏ None, —è–∫—â–æ –ø—Ä–∏—Ö–æ–≤–∞–Ω–æ
                    'comments_count': vinfo.get('comment_count'),  # –ú–æ–∂–µ –±—É—Ç–∏ None
                    'duration': vinfo.get('duration', 0),
                    'publish_date': publish_date,
                    'thumbnail_url': vinfo.get('thumbnail'),
                    'url': vinfo.get('webpage_url', vurl)  # –ù–∞–¥–∞—î–º–æ –ø–µ—Ä–µ–≤–∞–≥—É webpage_url
                })
        except Exception as e:
            st.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏ –≤—ñ–¥–µ–æ {vurl}: {e}")
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ü–µ –≤—ñ–¥–µ–æ —ñ –ø–µ—Ä–µ—Ö–æ–¥–∏–º–æ –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ

    return videos


def fetch_comments(video_url, pct_str="100%"):
    """
    –ó–±–∏—Ä–∞—î –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ —á–µ—Ä–µ–∑ YouTube Data API v3.
    –ü–æ–≤–µ—Ä—Ç–∞—î pct_str% –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤, –∑ –ª–∞–π–∫–∞–º–∏ —ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—è–º–∏.
    """
    if not YT_API_KEY:
        st.error("–ù–µ –∑–∞–¥–∞–Ω–∏–π –∫–ª—é—á API YouTube (YOUTUBE_API_KEY) –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤.")
        return []

    video_id_match = re.search(r"(?:v=|youtu\.be/|shorts/|embed/|watch\?v=|\&v=)([\w-]{11})", video_url)
    if not video_id_match:
        if re.match(r"^[\w-]{11}$", video_url):  # –Ø–∫—â–æ —Ü–µ –≤–∂–µ ID
            video_id = video_url
        else:
            st.error(f"–ù–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç URL –∞–±–æ ID –≤—ñ–¥–µ–æ –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤: {video_url}")
            return []
    else:
        video_id = video_id_match.group(1)

    try:
        youtube_service = build("youtube", "v3", developerKey=YT_API_KEY)
        comments_data = []
        next_page_token = None
        max_comments_limit = 1000  # –ó–∞–≥–∞–ª—å–Ω–µ –æ–±–º–µ–∂–µ–Ω–Ω—è –Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –æ–¥–Ω–æ–≥–æ –≤—ñ–¥–µ–æ

        while True:
            response = youtube_service.commentThreads().list(
                part="snippet,replies",
                videoId=video_id,
                maxResults=100,  # –ú–∞–∫—Å–∏–º—É–º –∑–∞ –æ–¥–∏–Ω –∑–∞–ø–∏—Ç
                pageToken=next_page_token,
                textFormat="plainText"
            ).execute()

            for item in response.get("items", []):
                top_level_comment = item.get("snippet", {}).get("topLevelComment", {}).get("snippet", {})
                replies = item.get("replies", {}).get("comments", [])

                comments_data.append({
                    "text": top_level_comment.get("textDisplay", ""),
                    "likes": top_level_comment.get("likeCount", 0),
                    "replies": replies
                })
                if len(comments_data) >= max_comments_limit:
                    break

            next_page_token = response.get("nextPageToken")
            if not next_page_token or len(comments_data) >= max_comments_limit:
                break

        # –û–±—Ä–æ–±–∫–∞ –≤—ñ–¥—Å–æ—Ç–∫–∞
        if pct_str != "100%":
            try:
                percentage_to_fetch = float(pct_str.strip('%')) / 100
                num_to_return = int(len(comments_data) * percentage_to_fetch)
                return comments_data[:num_to_return]
            except ValueError:
                st.warning(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –≤—ñ–¥—Å–æ—Ç–∫–∞: {pct_str}. –ü–æ–≤–µ—Ä—Ç–∞—é –≤—Å—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ.")

        return comments_data
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ —á–µ—Ä–µ–∑ YouTube API: {e}")
        return []


# ‚úÖ GPT-–∞–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–æ–Ω—É
def gpt_sentiment_analysis(comments_texts_list, model="gpt-3.5-turbo"):
    if not client:  # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞, —á–∏ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π –∫–ª—ñ—î–Ω—Ç OpenAI
        st.error("–ö–ª—ñ—î–Ω—Ç OpenAI –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π (–ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ API –∫–ª—é—á).")
        return {"positive": 0, "neutral": 0, "negative": 0, "error": "OpenAI client not initialized."}

    if not comments_texts_list:
        return {"positive": 0, "neutral": 0, "negative": 0, "error": "–ù–µ–º–∞—î —Ç–µ–∫—Å—Ç—ñ–≤ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É."}

    clean_comments_list = [c for c in comments_texts_list if isinstance(c, str) and c.strip()]
    if not clean_comments_list:
        return {"positive": 0, "neutral": 0, "negative": 0,
                "error": "–ü—ñ—Å–ª—è –æ—á–∏—Å—Ç–∫–∏ –Ω–µ –∑–∞–ª–∏—à–∏–ª–æ—Å—è –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É."}

    # –û–±–º–µ–∂—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø–∏—Ç—É –¥–æ GPT
    sample_comments = clean_comments_list[:100]

    prompt_text = f"""
–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –Ω–∞—Å—Ç—É–ø–Ω—ñ —é—Ç—É–±-–∫–æ–º–µ–Ω—Ç–∞—Ä—ñ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é. –ü–æ—Ä–∞—Ö—É–π —Ç–∞ –ø–æ–≤–µ—Ä–Ω–∏ –ø—Ä–∏–±–ª–∏–∑–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å:
- –ø–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö (positive)
- –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∏—Ö (neutral)
- –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö (negative)

–§–æ—Ä–º–∞—Ç –≤–∏–≤–æ–¥—É –º–∞—î –±—É—Ç–∏ —Ç–∞–∫–∏–º (–ª–∏—à–µ —Ü—ñ —Ç—Ä–∏ —Ä—è–¥–∫–∏, –¥–µ X, Y, Z - —Ü—ñ–ª—ñ —á–∏—Å–ª–∞):
positive: X
neutral: Y
negative: Z

–ö–æ–º–µ–Ω—Ç–∞—Ä—ñ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É:
{chr(10).join(sample_comments)}
""".strip()

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt_text}],
            temperature=0.3,
            max_tokens=100,
        )
        api_response_text = response.choices[0].message.content.strip()

        sentiment_results = {"positive": 0, "neutral": 0, "negative": 0}
        for line_text in api_response_text.lower().splitlines():
            line_text = line_text.strip()
            if "positive:" in line_text:
                found_numbers = re.findall(r"\d+", line_text)
                if found_numbers: sentiment_results["positive"] = int(found_numbers[0])
            elif "neutral:" in line_text:
                found_numbers = re.findall(r"\d+", line_text)
                if found_numbers: sentiment_results["neutral"] = int(found_numbers[0])
            elif "negative:" in line_text:
                found_numbers = re.findall(r"\d+", line_text)
                if found_numbers: sentiment_results["negative"] = int(found_numbers[0])

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞, —á–∏ GPT –ø–æ–≤–µ—Ä–Ω—É–≤ —â–æ—Å—å —Å—Ö–æ–∂–µ –Ω–∞ –æ—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if sum(sentiment_results.values()) == 0 and not any(
                kw in api_response_text.lower() for kw in ["positive", "neutral", "negative"]):
            return {"positive": 0, "neutral": 0, "negative": 0,
                    "error": f"GPT –ø–æ–≤–µ—Ä–Ω—É–≤ –Ω–µ–∑—Ä–æ–∑—É–º—ñ–ª—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ: {api_response_text}"}
        return sentiment_results

    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ GPT –ø—Ä–∏ –∞–Ω–∞–ª—ñ–∑—ñ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ: {e}")
        return {"positive": 0, "neutral": 0, "negative": 0, "error": str(e)}


def gpt_comment_summary(comments_texts_list, model="gpt-3.5-turbo"):
    if not client:  # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–ª—ñ—î–Ω—Ç–∞ OpenAI
        st.error("–ö–ª—ñ—î–Ω—Ç OpenAI –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π (–ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ API –∫–ª—é—á).")
        return "–ö–ª—ñ—î–Ω—Ç OpenAI –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π."

    if not comments_texts_list:
        return "–ù–µ–º–∞—î –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—É."

    clean_comments_list = [c for c in comments_texts_list if isinstance(c, str) and c.strip()]
    if not clean_comments_list:
        return "–ü—ñ—Å–ª—è –æ—á–∏—Å—Ç–∫–∏ –Ω–µ –∑–∞–ª–∏—à–∏–ª–æ—Å—è –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—É."

    sample_for_summary = random.sample(clean_comments_list, min(100, len(clean_comments_list)))

    prompt_text = f"""
–¢–æ–±—ñ –Ω–∞–¥–∞–Ω–æ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –ø—ñ–¥ –≤—ñ–¥–µ–æ –∑ YouTube —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é.

1. –ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –∞–Ω–∞–ª—ñ–∑ –Ω–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à–∏—Ö —Ç–µ–º –∞–±–æ –Ω–∞—Å—Ç—Ä–æ—ó–≤ —É —Ü–∏—Ö –∫–æ–º–µ–Ω—Ç–∞—Ä—è—Ö (2-3 —Ä–µ—á–µ–Ω–Ω—è).
2. –£–∑–∞–≥–∞–ª—å–Ω–∏ (–ø–æ 1-2 —Ä–µ—á–µ–Ω–Ω—è –Ω–∞ –∫–æ–∂–µ–Ω –ø—É–Ω–∫—Ç):
   - –©–æ –Ω–∞–π–±—ñ–ª—å—à–µ —Å–ø–æ–¥–æ–±–∞–ª–æ—Å—å –≥–ª—è–¥–∞—á–∞–º (—è–∫—â–æ —Ü–µ –≤–∏–¥–Ω–æ –∑ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤)?
   - –©–æ –∑–∞–ª–∏—à–∏–ª–æ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–µ –≤—Ä–∞–∂–µ–Ω–Ω—è?
   - –©–æ –≤–∏–∫–ª–∏–∫–∞–ª–æ –Ω–µ–≥–∞—Ç–∏–≤ —á–∏ –∫—Ä–∏—Ç–∏–∫—É?
3. –ó—Ä–æ–±–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –≤–∏—Å–Ω–æ–≤–æ–∫ (1-2 —Ä–µ—á–µ–Ω–Ω—è) –ø—Ä–æ –∑–∞–≥–∞–ª—å–Ω–µ –≤—Ä–∞–∂–µ–Ω–Ω—è –∞—É–¥–∏—Ç–æ—Ä—ñ—ó –≤—ñ–¥ –≤—ñ–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ü–∏—Ö –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤.

–ë—É–¥—å –ª–∞—Å–∫–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä—É–π –≤—ñ–¥–ø–æ–≤—ñ–¥—å —á—ñ—Ç–∫–æ.

–ö–æ–º–µ–Ω—Ç–∞—Ä—ñ:
{chr(10).join(sample_for_summary)}
""".strip()

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt_text}],
            temperature=0.7,
            max_tokens=800,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ GPT –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø—ñ–¥—Å—É–º–∫—É –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤: {e}")
        return f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ GPT: {e}"


def format_duration(seconds_total):
    """–§–æ—Ä–º–∞—Ç—É—î —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∑ —Å–µ–∫—É–Ω–¥ —É HH:MM:SS."""
    if not isinstance(seconds_total, (int, float)) or seconds_total < 0:
        return "00:00:00"
    h = int(seconds_total // 3600)
    m = int((seconds_total % 3600) // 60)
    s = int(seconds_total % 60)
    return f"{h:02}:{m:02}:{s:02}"


# --- –û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–∏ (—Ç—ñ–ª—å–∫–∏ "–ê–Ω–∞–ª—ñ–∑ –≤—ñ–¥–µ–æ") ---

video_url_input = st.text_input(
    "URL –≤—ñ–¥–µ–æ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É:",
    placeholder="–í—Å—Ç–∞–≤—Ç–µ URL YouTube –≤—ñ–¥–µ–æ...",
    key="main_video_url_input"  # –£–Ω—ñ–∫–∞–ª—å–Ω–∏–π –∫–ª—é—á –¥–ª—è —Ü—å–æ–≥–æ –ø–æ–ª—è –≤–≤–æ–¥—É
)

# –û–ø—Ü—ñ—ó –¥–ª—è –≤–∏–±–æ—Ä—É –≤—ñ–¥—Å–æ—Ç–∫–∞ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤
comments_percentage_options = {"–í—Å—ñ": "100%", "10%": "10%", "50%": "50%"}  # –°–ª–æ–≤–Ω–∏–∫ –¥–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ
selected_display_percentage = st.selectbox(
    "–Ø–∫—É —á–∞—Å—Ç–∫—É –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏:",
    list(comments_percentage_options.keys()),
    index=0,  # "–í—Å—ñ" –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º
    key="comments_percentage_selector"
)
percentage_to_fetch_str = comments_percentage_options[selected_display_percentage]

if st.button("üöÄ –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –≤—ñ–¥–µ–æ", key="analyze_this_video_button"):
    if not video_url_input:
        st.error("–ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å URL –≤—ñ–¥–µ–æ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.")
    else:
        # 1. –û—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –≤—ñ–¥–µ–æ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é yt_dlp
        with st.spinner("–ó–±—ñ—Ä –¥–∞–Ω–∏—Ö –ø—Ä–æ –≤—ñ–¥–µ–æ..."):
            video_details = None
            try:
                ydl_opts_video = {
                    'quiet': True,
                    'no_warnings': True,
                    'skip_download': True,
                    'ignoreerrors': True,
                }
                with yt_dlp.YoutubeDL(ydl_opts_video) as ydl:
                    video_details = ydl.extract_info(video_url_input, download=False)
            except Exception as e:
                st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ –¥–∞–Ω–∏—Ö –≤—ñ–¥–µ–æ —á–µ—Ä–µ–∑ yt_dlp: {e}")

        if not video_details:
            st.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –¥–ª—è –≤—ñ–¥–µ–æ –∑–∞ URL: {video_url_input}")
        else:
            st.subheader(f"–ê–Ω–∞–ª—ñ–∑ –≤—ñ–¥–µ–æ: {video_details.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∏')}")

            col_thumb, col_info = st.columns([1, 3])  # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ–±–∫–ª–∞–¥–∏–Ω–∫–∏ —Ç–∞ —ñ–Ω—Ñ–æ
            with col_thumb:
                if video_details.get('thumbnail'):
                    st.image(video_details.get('thumbnail'), width=240)
                else:
                    st.write("üñºÔ∏è (–Ω–µ–º–∞—î –æ–±–∫–ª–∞–¥–∏–Ω–∫–∏)")

            with col_info:
                st.markdown(f"**–ù–∞–∑–≤–∞:** {video_details.get('title', 'N/A')}")
                st.markdown(f"**–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å:** {format_duration(video_details.get('duration', 0))}")
                st.markdown(f"**–ü–µ—Ä–µ–≥–ª—è–¥–∏:** {video_details.get('view_count', 0):,}")  # –§–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è —á–∏—Å–ª–∞ –∑ –∫–æ–º–∞–º–∏

                likes_count = video_details.get('like_count')
                st.markdown(
                    f"**–õ–∞–π–∫–∏:** {likes_count:,}" if isinstance(likes_count, int) else "N/A (–ø—Ä–∏—Ö–æ–≤–∞–Ω–æ –∞–±–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ)")

                comment_count_overall = video_details.get('comment_count')
                st.markdown(f"**–ö–æ–º–µ–Ω—Ç–∞—Ä—ñ (–∑–∞–≥–∞–ª–æ–º):** {comment_count_overall:,}" if isinstance(comment_count_overall,
                                                                                                int) else "N/A")

                upload_date_str = video_details.get('upload_date')  # –§–æ—Ä–º–∞—Ç YYYYMMDD
                if upload_date_str:
                    try:
                        publish_date_dt = datetime.strptime(upload_date_str, '%Y%m%d').date()
                        st.markdown(f"**–î–∞—Ç–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó:** {publish_date_dt.strftime('%d.%m.%Y')}")
                    except ValueError:
                        st.markdown(f"**–î–∞—Ç–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó:** {upload_date_str} (–Ω–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø–∞—Ä—Å–∏—Ç–∏ —Ñ–æ—Ä–º–∞—Ç)")
                else:
                    st.markdown("**–î–∞—Ç–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó:** N/A")

            # 2. –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ç–∞ –∞–Ω–∞–ª—ñ–∑ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤
            st.markdown("---")  # –†–æ–∑–¥—ñ–ª—é–≤–∞—á
            st.subheader("üìà –ê–Ω–∞–ª—ñ–∑ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–æ –≤—ñ–¥–µ–æ")

            with st.spinner(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –∞–Ω–∞–ª—ñ–∑ {selected_display_percentage} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤..."):
                fetched_comments_data = fetch_comments(video_url_input, pct=percentage_to_fetch_str)

            if not fetched_comments_data:
                st.info("–ö–æ–º–µ–Ω—Ç–∞—Ä—ñ –¥–æ —Ü—å–æ–≥–æ –≤—ñ–¥–µ–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, —ó—Ö –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏, –∞–±–æ –æ–±—Ä–∞–Ω–æ 0%.")
            else:
                # –í–∏—Ç—è–≥—É—î–º–æ –ª–∏—à–µ —Ç–µ–∫—Å—Ç–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á—ñ –≤ GPT
                comment_texts_for_gpt = [
                    comment.get("text", "") for comment in fetched_comments_data
                    if
                    isinstance(comment, dict) and isinstance(comment.get("text"), str) and comment.get("text").strip()
                ]

                if not comment_texts_for_gpt:
                    st.warning(
                        "–•–æ—á–∞ –¥–∞–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –±—É–ª–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ, —Ç–µ–∫—Å—Ç–æ–≤–∏–π –≤–º—ñ—Å—Ç –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –≤—ñ–¥—Å—É—Ç–Ω—ñ–π –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π.")
                else:
                    # GPT-–∞–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ
                    st.markdown("##### –¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ (–∑–∞ –≤–µ—Ä—Å—ñ—î—é GPT):")
                    sentiment_gpt_result = gpt_sentiment_analysis(comment_texts_for_gpt)

                    if "error" not in sentiment_gpt_result or sum(
                            v for v in sentiment_gpt_result.values() if isinstance(v, int)) > 0:
                        total_valid_sentiments = sum(
                            v for v in sentiment_gpt_result.values() if isinstance(v, int)) or 1

                        pos_pct = (sentiment_gpt_result.get('positive', 0) / total_valid_sentiments) * 100
                        neu_pct = (sentiment_gpt_result.get('neutral', 0) / total_valid_sentiments) * 100
                        neg_pct = (sentiment_gpt_result.get('negative', 0) / total_valid_sentiments) * 100

                        bar_len = 20  # –î–æ–≤–∂–∏–Ω–∞ –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä—É
                        pos_bar_len = int(bar_len * pos_pct / 100)
                        neu_bar_len = int(bar_len * neu_pct / 100)
                        # –ó–∞–ª–∏—à–æ–∫ –¥–ª—è –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö, —â–æ–± —Å—É–º–∞ –Ω–µ –ø–µ—Ä–µ–≤–∏—â—É–≤–∞–ª–∞ bar_len
                        neg_bar_len = max(0, bar_len - pos_bar_len - neu_bar_len)

                        sentiment_display_bar = "üü©" * pos_bar_len + "üü®" * neu_bar_len + "üü•" * neg_bar_len
                        st.markdown(f"{sentiment_display_bar}  ‚úÖ{pos_pct:.0f}% üòê{neu_pct:.0f}% ‚ùå{neg_pct:.0f}%")
                        if "error" in sentiment_gpt_result and sentiment_gpt_result["error"]:
                            st.caption(f"–ü—Ä–∏–º—ñ—Ç–∫–∞ —â–æ–¥–æ –∞–Ω–∞–ª—ñ–∑—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ: {sentiment_gpt_result['error']}")
                    else:
                        st.warning(
                            f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –∞–Ω–∞–ª—ñ–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ –≤—ñ–¥ GPT. {sentiment_gpt_result.get('error', '–ü–æ–≤–µ—Ä–Ω—É—Ç–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.')}")

                    # GPT-–∞–Ω–∞–ª—ñ—Ç–∏–∫–∞: –∑–∞–≥–∞–ª—å–Ω–∏–π –ø—ñ–¥—Å—É–º–æ–∫ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤
                    st.markdown("##### –ó–∞–≥–∞–ª—å–Ω–∏–π –ø—ñ–¥—Å—É–º–æ–∫ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ (–∑–∞ –≤–µ—Ä—Å—ñ—î—é GPT):")
                    summary_from_gpt = gpt_comment_summary(comment_texts_for_gpt)
                    st.markdown(summary_from_gpt)

                    # –¢–æ–ø-10 –Ω–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à–∏—Ö –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤
                    st.markdown("##### üî• –¢–æ–ø-10 –Ω–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à–∏—Ö –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ (–∑–∞ –ª–∞–π–∫–∞–º–∏):")

                    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ, –¥–µ 'likes' —î —á–∏—Å–ª–æ–º
                    comments_with_likes = [c for c in fetched_comments_data if isinstance(c.get('likes'), int)]

                    if not comments_with_likes:
                        st.info("–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—Ä–æ –ª–∞–π–∫–∏ –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–æ–ø—É.")
                    else:
                        top_10_comments = sorted(comments_with_likes, key=lambda x: x['likes'], reverse=True)[:10]
                        for i, comment_detail in enumerate(top_10_comments):
                            st.markdown(f"---\n**{i + 1}.** üëç {comment_detail['likes']:,} –ª–∞–π–∫—ñ–≤")
                            st.markdown(f"> {comment_detail['text']}")

                            replies_list = comment_detail.get("replies", [])
                            if replies_list:
                                # –§—ñ–ª—å—Ç—Ä—É—î–º–æ —Ç–∞ —Å–æ—Ä—Ç—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                                valid_replies_list = [
                                    r for r in replies_list
                                    if isinstance(r, dict) and isinstance(r.get("snippet", {}).get("likeCount"), int)
                                ]
                                sorted_replies_list = sorted(
                                    valid_replies_list,
                                    key=lambda r_item: r_item["snippet"]["likeCount"],
                                    reverse=True
                                )[:5]  # –û–±–º–µ–∂–µ–Ω–Ω—è –Ω–∞ 5 –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π

                                if sorted_replies_list:
                                    with st.expander(f"üí¨ –ü–æ–∫–∞–∑–∞—Ç–∏ –¥–æ {len(sorted_replies_list)} –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π"):
                                        for reply_item in sorted_replies_list:
                                            reply_snippet_data = reply_item.get("snippet", {})
                                            st.markdown(
                                                f"‚Ü≥ {reply_snippet_data.get('textDisplay', '')}  _(üëç {reply_snippet_data.get('likeCount', 0):,})_"
                                            )
